{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audioop import mul\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4545],\n",
       "        [-0.7868],\n",
       "        [ 0.9084],\n",
       "        [-1.6203],\n",
       "        [ 0.1068],\n",
       "        [ 0.2312],\n",
       "        [ 0.4612],\n",
       "        [ 1.0168],\n",
       "        [-0.8705],\n",
       "        [-0.9826]], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.FloatTensor(10,1).normal_(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1536,)\n",
      "(1024,)\n"
     ]
    }
   ],
   "source": [
    "# image_feature\n",
    "vis_emb = np.load(r\"C:\\HolisticVideoUnderstanding\\sampled_test\\applying cream\\0PgfOKP1Ow0_66\\InceptionResnetV2_MaxPooling.npz\")[\"InceptionResnetV2\"]\n",
    "print(vis_emb.shape)\n",
    "\n",
    "# textual_feature\n",
    "txt_emb = np.load(r\"C:\\HolisticVideoUnderstanding\\sampled_test\\applying cream\\0PgfOKP1Ow0_66\\Elmo_Mean.npz\")[\"Elmo\"]\n",
    "print(txt_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Loader\n",
    "class HVUDataset(Dataset):\n",
    "    def __init__(self, n_trial):\n",
    "        self.total = n_trial\n",
    "        \n",
    "    def __len__(self):        \n",
    "        return self.total # 4\n",
    "    \n",
    "    # this function will return one n-way, k-shot set\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        #return torch.randperm(idx)\n",
    "        return \"erol___\"+str(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = HVUDataset(n_trial=30)\n",
    "    \n",
    "train_loader = DataLoader(dataset= ds, batch_size = 10, shuffle=True, num_workers = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['erol___24', 'erol___5', 'erol___19', 'erol___2', 'erol___22', 'erol___15', 'erol___29', 'erol___0', 'erol___26', 'erol___14']\n",
      "['erol___8', 'erol___25', 'erol___7', 'erol___20', 'erol___6', 'erol___16', 'erol___1', 'erol___17', 'erol___12', 'erol___10']\n",
      "['erol___27', 'erol___11', 'erol___23', 'erol___21', 'erol___3', 'erol___13', 'erol___9', 'erol___4', 'erol___28', 'erol___18']\n"
     ]
    }
   ],
   "source": [
    "for local_batch in train_loader:\n",
    "    print(local_batch)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1., 1., 1.]), array([2., 2., 2.]), array([3., 3., 3.]), array([10., 10., 10.]), array([20., 20., 20.]), array([30., 30., 30.])]\n",
      "[array([4., 4., 4.]), array([40., 40., 40.])]\n"
     ]
    }
   ],
   "source": [
    "empty = []\n",
    "empty_test = []\n",
    "\n",
    "a = [np.ones(3)*1, np.ones(3)*2, np.ones(3)*3, np.ones(3)*4]\n",
    "b = [np.ones(3)*10, np.ones(3)*20, np.ones(3)*30, np.ones(3)*40]\n",
    "\n",
    "empty.extend(a[:-1])\n",
    "empty_test.extend(a[-1:])\n",
    "\n",
    "empty.extend(b[:-1])\n",
    "empty_test.extend(b[-1:])\n",
    "\n",
    "\n",
    "print(empty)\n",
    "print(empty_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "normalizer = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_f = np.load(\"C:/HolisticVideoUnderstanding/uniform_train/air drumming/qF1dEUpUbNA_80/InceptionResnetV2_MaxPooling.npz\")['InceptionResnetV2']\n",
    "textual_f = np.load(\"C:/HolisticVideoUnderstanding/uniform_train/air drumming/qF1dEUpUbNA_80/Elmo_Mean.npz\")['Elmo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.72966594, 0.07658113, 3.2027264)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(visual_f), np.min(visual_f), np.max(visual_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_visual_f = normalizer.fit_transform(np.float32(visual_f).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20891058, 0.0, 1.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(new_visual_f), np.min(new_visual_f), np.max(new_visual_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.013344703, -2.2783346, 1.8741663)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(textual_f), np.min(textual_f), np.max(textual_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_textual_f = normalizer.fit_transform(np.float32(textual_f).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.545452, 0.0, 1.0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(new_textual_f), np.min(new_textual_f), np.max(new_textual_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Distribution Aware Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = [1,1,1,1,1,2,2,2,2,2,0,0,0,0,0]\n",
    "n_way = 3\n",
    "k_shot = 5\n",
    "\n",
    "# Training Stage\n",
    "mu_1 = torch.normal(10, 1, (5,64))\n",
    "mu_2 = torch.normal(-30, 1, (5,64))\n",
    "mu_3 = torch.normal(170, 1, (5,64))\n",
    "\n",
    "logvar_1 = torch.normal(10, 1, (5,64))\n",
    "logvar_2 = torch.normal(-30, 1, (5,64))\n",
    "logvar_3 = torch.normal(170, 1, (5,64))\n",
    "\n",
    "mus = torch.cat((mu_1, mu_2, mu_3))\n",
    "logvars = torch.cat((logvar_1, logvar_2, logvar_3))\n",
    "\n",
    "# Testing Stage\n",
    "mu_1 = torch.normal(7, 1, (5,64))\n",
    "mu_2 = torch.normal(-20, 1, (5,64))\n",
    "mu_3 = torch.normal(100, 1, (5,64))\n",
    "\n",
    "logvar_1 = torch.normal(7, 1, (5,64))\n",
    "logvar_2 = torch.normal(-20, 1, (5,64))\n",
    "logvar_3 = torch.normal(100, 1, (5,64))\n",
    "\n",
    "test_mus = torch.cat((mu_1, mu_2, mu_3))\n",
    "test_logvars = torch.cat((logvar_1, logvar_2, logvar_3))\n",
    "\n",
    "#mus = torch.rand((15,1,64)).reshape((n_way*k_shot, 64))\n",
    "#logvars = torch.rand((15,1,64)).reshape((n_way*k_shot, 64))\n",
    "#test_mus = torch.rand((15,1,64)).reshape((n_way*k_shot, 64))\n",
    "#test_logvars = torch.rand((15,1,64)).reshape((n_way*k_shot, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15, 64]),\n",
       " torch.Size([15, 64]),\n",
       " torch.Size([15, 64]),\n",
       " torch.Size([15, 64]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mus.shape, logvars.shape, test_mus.shape, test_logvars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.a) Class mus, logvar construction stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1 / k_shot\n",
    "avg_train_mus = []\n",
    "avg_train_vars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(mus) - 1, k_shot):\n",
    "    \n",
    "    avg_mu = np.mean(mus[i: i + k_shot].cpu().detach().numpy(), axis=0)\n",
    "    \n",
    "    class_mu = mus[i: i + k_shot].cpu().detach().numpy()\n",
    "    class_variance = logvars[i: i + k_shot].cpu().detach().numpy()\n",
    "        \n",
    "    # sinif ici her bir mu variance al\n",
    "    avg_var = [0.0] * 64\n",
    "    for j in range(len(class_variance)):\n",
    "        \n",
    "        # For the 1st, 2nd, 3rd solutions            \n",
    "        if k_shot != 1:\n",
    "            avg_var += (( 1/k_shot * class_variance[j] ) + (1/k_shot * ((class_mu - avg_mu)**2)))\n",
    "        # If there is only 1 sample, avg_var equals to that sample's var\n",
    "        else:\n",
    "            avg_var += class_variance[j]        \n",
    "            \n",
    "    # class oriented var\n",
    "    avg_train_vars.append(avg_var)\n",
    "    \n",
    "    # class oriented mu\n",
    "    avg_train_mus.append(avg_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64,), (64,), (64,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_train_mus[0].shape, avg_train_mus[1].shape, avg_train_mus[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 64), (5, 64), (5, 64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_train_vars[0].shape, avg_train_vars[1].shape, avg_train_vars[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Testing stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_train_mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "gt_tensor = np.array(gt, dtype=np.int32)\n",
    "gt_tensor = torch.from_numpy(gt_tensor).type(torch.long).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(1.8231)\n",
      "----------\n",
      "0\n",
      "tensor(1.8080)\n",
      "----------\n",
      "0\n",
      "tensor(1.8079)\n",
      "----------\n",
      "0\n",
      "tensor(1.7971)\n",
      "----------\n",
      "0\n",
      "tensor(1.8003)\n",
      "----------\n",
      "1\n",
      "tensor(2.2241)\n",
      "----------\n",
      "1\n",
      "tensor(2.2272)\n",
      "----------\n",
      "1\n",
      "tensor(2.2249)\n",
      "----------\n",
      "1\n",
      "tensor(2.2248)\n",
      "----------\n",
      "1\n",
      "tensor(2.2199)\n",
      "----------\n",
      "2\n",
      "tensor(76.8491)\n",
      "----------\n",
      "2\n",
      "tensor(77.0428)\n",
      "----------\n",
      "2\n",
      "tensor(77.3163)\n",
      "----------\n",
      "2\n",
      "tensor(77.2453)\n",
      "----------\n",
      "2\n",
      "tensor(77.2331)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "test_pred_labels = []\n",
    "\n",
    "for i in range(len(test_mus)):\n",
    "    test_dist = torch.distributions.Normal(test_mus[i],test_logvars[i])\n",
    "\n",
    "    local_scores = []\n",
    "    for j in range(len(avg_train_mus)):\n",
    "        \n",
    "        # KL divergence\n",
    "        train_dist = torch.distributions.Normal(torch.Tensor(avg_train_mus[j]), torch.Tensor(avg_train_vars[j]))\n",
    "        scr = torch.distributions.kl_divergence(test_dist, train_dist).mean()\n",
    "        #print(\"{}.th sample, {}.th class, SCORE:{}\".format(i,j,scr))\n",
    "        local_scores.append(scr)\n",
    "        \n",
    "    #print(local_scores)\n",
    "    \n",
    "    local_similarities = torch.from_numpy(np.array([-1 * elem for elem in local_scores])).reshape(1,-1)\n",
    "    \n",
    "    # categorical cross entropy loss    \n",
    "    #print(local_similarities)    \n",
    "    #print(gt_tensor[i])\n",
    "    cc_loss = loss(local_similarities, gt_tensor[i])\n",
    "    \n",
    "    # min of kl divergence for class decision\n",
    "    pred_cls_idx = np.argmin(local_scores)\n",
    "    \n",
    "    print(pred_cls_idx)\n",
    "    print(cc_loss)\n",
    "    print(\"----------\")\n",
    "        \n",
    "    test_pred_labels.append(pred_cls_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7976169420317689, 0.16151991692720932, 0.04086314104102191]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = [-0.2025, -1.7995, -3.1739]\n",
    "raw_exp = [np.exp(elem) for elem in raw]\n",
    "probabilities = [elem/np.sum(raw_exp) for elem in raw_exp]\n",
    "\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred \t G.T.\n",
      "0 \t 1\n",
      "0 \t 1\n",
      "0 \t 1\n",
      "0 \t 1\n",
      "0 \t 1\n",
      "1 \t 2\n",
      "1 \t 2\n",
      "1 \t 2\n",
      "1 \t 2\n",
      "1 \t 2\n",
      "2 \t 0\n",
      "2 \t 0\n",
      "2 \t 0\n",
      "2 \t 0\n",
      "2 \t 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred \\t G.T.\")\n",
    "for i in range(len(test_pred_labels)):\n",
    "    print(\"{} \\t {}\".format(test_pred_labels[i], gt[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       5.0\n",
      "           1       0.00      0.00      0.00       5.0\n",
      "           2       0.00      0.00      0.00       5.0\n",
      "\n",
      "    accuracy                           0.00      15.0\n",
      "   macro avg       0.00      0.00      0.00      15.0\n",
      "weighted avg       0.00      0.00      0.00      15.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(gt, test_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd5a1bf88f2223e086c21887dd6e48bf3dffebb406704354dbccd7318b75d67b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
