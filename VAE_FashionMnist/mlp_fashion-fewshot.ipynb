{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "# prerequisites\n",
    "from tensorflow.keras.datasets import cifar10, fashion_mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Flatten, Conv2D, Reshape, Conv2DTranspose, BatchNormalization\n",
    "from tensorflow.keras.activations import elu\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import binary_crossentropy, mean_squared_error\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import stats as sps \n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# data load\n",
    "(x_tr, y_tr), (x_te, y_te) = fashion_mnist.load_data()\n",
    "x_tr, x_te = x_tr.astype('float32')/255., x_te.astype('float32')/255.\n",
    "x_tr, x_te = x_tr.reshape(x_tr.shape[0], -1), x_te.reshape(x_te.shape[0], -1)\n",
    "print(x_tr.shape, x_te.shape)\n",
    "\n",
    "# network parameters\n",
    "batch_size, n_epoch = 100, 50\n",
    "n_hidden, z_dim = 256, 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_f, y_f = [], [] \n",
    "rmv_idx = []\n",
    "\n",
    "for i in range(10): \n",
    "    if i % 2 != 0: \n",
    "        \n",
    "        # 1,3,5,7,9 \n",
    "        idf_i = list(np.where(y_tr == i)[0]) \n",
    "        \n",
    "        y_f.append([i]*len(idf_i))\n",
    "        x_f.append(x_tr[idf_i]) \n",
    "        \n",
    "            \n",
    "        # remove elements by index list \n",
    "        rmv_idx += idf_i\n",
    "             \n",
    "x_tr = np.delete(x_tr, rmv_idx, axis=0) \n",
    "y_tr = np.delete(y_tr, rmv_idx, axis=0) \n",
    "        \n",
    "x_f = np.array(x_f) \n",
    "y_f = np.array(y_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_tr.shape, x_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "x = Input(shape=(x_tr.shape[1:]))\n",
    "x_encoded = Dense(n_hidden, activation='relu')(x)\n",
    "x_encoded = Dense(n_hidden//2, activation='relu')(x_encoded)\n",
    "z  = Dense(z_dim)(x_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "z_decoder1 = Dense(n_hidden//2, activation='relu')\n",
    "z_decoder2 = Dense(n_hidden, activation='relu')\n",
    "y_decoder = Dense(x_tr.shape[1], activation='sigmoid')\n",
    "\n",
    "z_decoded = z_decoder1(z)\n",
    "z_decoded = z_decoder2(z_decoded)\n",
    "y = y_decoder(z_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          200960      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           2064        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          2176        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          33024       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 784)          201488      dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast (TFOpLambda)            (None, 784)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor (TFOpLambd (None, 784)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.keras.backend.binary_crossen (None, 784)          0           tf.cast[0][0]                    \n",
      "                                                                 tf.convert_to_tensor[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None,)              0           tf.keras.backend.binary_crossentr\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None,)              0           tf.math.reduce_mean[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_loss (AddLoss)              (None,)              0           tf.math.multiply[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 472,608\n",
      "Trainable params: 472,608\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# loss\n",
    "reconstruction_loss = binary_crossentropy(x, y) * x_tr.shape[1]\n",
    "mlp_loss = reconstruction_loss\n",
    "\n",
    "# build model\n",
    "mlp = Model(x, y)\n",
    "mlp.add_loss(mlp_loss)\n",
    "mlp.compile(optimizer='rmsprop')\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 362.6592\n",
      "Epoch 2/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 298.6260\n",
      "Epoch 3/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 288.8537\n",
      "Epoch 4/50\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 283.8091\n",
      "Epoch 5/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 280.5961\n",
      "Epoch 6/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 278.1391\n",
      "Epoch 7/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 275.0856\n",
      "Epoch 8/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 273.3365\n",
      "Epoch 9/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 272.4185\n",
      "Epoch 10/50\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 271.4098\n",
      "Epoch 11/50\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 270.7336\n",
      "Epoch 12/50\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 269.1961\n",
      "Epoch 13/50\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 268.7355\n",
      "Epoch 14/50\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 268.4979\n",
      "Epoch 15/50\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 267.6480\n",
      "Epoch 16/50\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 267.6308\n",
      "Epoch 17/50\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 266.9765\n",
      "Epoch 18/50\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 266.1479\n",
      "Epoch 19/50\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 265.7051\n",
      "Epoch 20/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 265.3911\n",
      "Epoch 21/50\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 265.0491\n",
      "Epoch 22/50\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 265.5029\n",
      "Epoch 23/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 264.5890\n",
      "Epoch 24/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 264.4513\n",
      "Epoch 25/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 265.0308\n",
      "Epoch 26/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 264.1516\n",
      "Epoch 27/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 263.7451\n",
      "Epoch 28/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 263.6960\n",
      "Epoch 29/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 263.7430\n",
      "Epoch 30/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 263.4135\n",
      "Epoch 31/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 264.1564\n",
      "Epoch 32/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 263.4753\n",
      "Epoch 33/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 263.0762\n",
      "Epoch 34/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 262.9713\n",
      "Epoch 35/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 262.5679\n",
      "Epoch 36/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 262.7194\n",
      "Epoch 37/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 262.8383\n",
      "Epoch 38/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 262.8857\n",
      "Epoch 39/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 262.7009\n",
      "Epoch 40/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 262.1189\n",
      "Epoch 41/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 261.7900\n",
      "Epoch 42/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 261.5334\n",
      "Epoch 43/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 261.7197\n",
      "Epoch 44/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 261.9556\n",
      "Epoch 45/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 261.8289\n",
      "Epoch 46/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 261.9216\n",
      "Epoch 47/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 261.8428\n",
      "Epoch 48/50\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 261.4620\n",
      "Epoch 49/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 261.7114\n",
      "Epoch 50/50\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 261.1107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x146122d5608>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "mlp.fit(x_tr,\n",
    "       shuffle=True,\n",
    "       epochs=n_epoch,\n",
    "       batch_size=batch_size,\n",
    "       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 235,920\n",
      "Trainable params: 235,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build encoder\n",
    "encoder = Model(x, z)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               2176      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 784)               201488    \n",
      "=================================================================\n",
      "Total params: 236,688\n",
      "Trainable params: 236,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build decoder\n",
    "decoder_input = Input(shape=(z_dim,))\n",
    "_z_decoded = z_decoder1(decoder_input)\n",
    "_z_decoded = z_decoder2(_z_decoded)\n",
    "_y = y_decoder(_z_decoded)\n",
    "\n",
    "generator = Model(decoder_input, _y)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Michedev/VAE_anomaly_detection/blob/0a9eb14b7df226e8195c77d145a0f586ecbb6d67/VAE.py#L7\n",
    "def softplus(x):\n",
    "    return np.log(1+np.exp(x))\n",
    "\n",
    "from dictances import bhattacharyya, bhattacharyya_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 235,920\n",
      "Trainable params: 235,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "mlp_enc = Model(x, z)\n",
    "\n",
    "mlp_enc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "test_classes = []\n",
    "\n",
    "for i in range(y_f.shape[0]):\n",
    "    test_classes.append(y_f[i][0])\n",
    "    \n",
    "print(test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahalanobis Distance\n",
    "def mahalanobis(x=None, mean=None, cov=None):\n",
    "\n",
    "    x_mu = x - mean\n",
    "    inv_covmat = np.linalg.inv(cov)\n",
    "    \n",
    "    left = np.dot(x_mu, inv_covmat)\n",
    "        \n",
    "    mahal = np.dot(left, x_mu.T)\n",
    "        \n",
    "    return mahal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [09:16<00:00,  2.16it/s]\n"
     ]
    }
   ],
   "source": [
    "n_way = 3 # number of classes\n",
    "n_shot = 5 # number of samples per class\n",
    "\n",
    "n_trial = 0\n",
    "n_true = 0\n",
    "n_false = 0\n",
    "\n",
    "n_test = 1200\n",
    "\n",
    "g_train_images, g_train_gt_labels = np.load(str(n_way)+\"-\"+str(n_shot)+'.npz')[\"trainImage\"],np.load(str(n_way)+\"-\"+str(n_shot)+'.npz')[\"trainLabel\"]\n",
    "g_test_images, g_test_gt_labels = np.load(str(n_way)+\"-\"+str(n_shot)+'.npz')[\"testImage\"],np.load(str(n_way)+\"-\"+str(n_shot)+'.npz')[\"testLabel\"]\n",
    "g_ways = np.load(str(n_way)+\"-\"+str(n_shot)+'.npz')[\"ways\"]\n",
    "\n",
    "\n",
    "for ntest in tqdm(range(n_test)):\n",
    "    #print(\"Test Classes: {}\".format(test_classes))\n",
    "\n",
    "    # Load test data\n",
    "    test_images = g_test_images[ntest]\n",
    "    test_gt_labels = g_test_gt_labels[ntest]\n",
    "\n",
    "\n",
    "    train_images = g_train_images[ntest]\n",
    "    train_gt_labels = g_train_gt_labels[ntest]\n",
    "    \n",
    "    ways = g_ways[ntest]\n",
    "\n",
    "    train_mus = []\n",
    "\n",
    "    for image in train_images:\n",
    "        res = mlp_enc.predict(image)\n",
    "        mu_val = res[0][0]\n",
    "\n",
    "        train_mus.append(mu_val)\n",
    "\n",
    "\n",
    "    test_mus = []\n",
    "\n",
    "    for image in test_images:\n",
    "        res = mlp_enc.predict(image)\n",
    "        mu_val = res[0][0]\n",
    "\n",
    "        test_mus.append(mu_val)\n",
    "\n",
    "    ###########################\n",
    "    # Averaging mean's and mu's for each class\n",
    "    alpha = 1 / n_shot\n",
    "    avg_train_mus = []\n",
    "    \n",
    "    # average the mu variable\n",
    "    for i in range(0,len(train_mus) - 1, n_shot):\n",
    "        \n",
    "        avg_mu = np.mean(train_mus[i: i + n_shot], axis=0)\n",
    "        \n",
    "        # class oriented mu\n",
    "        avg_train_mus.append(avg_mu)\n",
    "\n",
    "\n",
    "    #print(train_mus, train_vars)\n",
    "    #print(avg_train_mus, avg_train_vars)\n",
    "\n",
    "    test_pred_labels= []\n",
    "    for i in range(len(test_mus)):\n",
    "        test_dist = test_mus[i]\n",
    "\n",
    "        local_scores = []\n",
    "        for j in range(len(avg_train_mus)):\n",
    "                        \n",
    "            scr = np.sqrt((test_dist - avg_train_mus[j])**2)\n",
    "            \n",
    "            local_scores.append(scr)\n",
    "\n",
    "        # get the minimum mahalanobis distance\n",
    "        pred_cls_idx = np.argmin(local_scores)\n",
    "        test_pred_labels.append(ways[pred_cls_idx])\n",
    "\n",
    "\n",
    "    for i in range(len(test_gt_labels)):\n",
    "        if test_gt_labels[i] == test_pred_labels[i]:\n",
    "            n_true += 1\n",
    "        else:\n",
    "            n_false += 1\n",
    "\n",
    "        n_trial += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-way: 3 - N-shot: 5\n",
      "Acc: 0.48611 in 1200 different trials\n"
     ]
    }
   ],
   "source": [
    "print(\"N-way: {} - N-shot: {}\".format(n_way,n_shot))\n",
    "print(\"Acc: {:.5f} in {} different trials\".format(n_true/n_trial, n_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####\n",
    "#####\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output of test images in terms of mu,sigma\n",
    "test_0 = scipy.stats.multivariate_normal(test_mus[0], np.diag(test_vars[0]))\n",
    "test_1 = scipy.stats.multivariate_normal(test_mus[1], np.diag(test_vars[1]))\n",
    "test_2 = scipy.stats.multivariate_normal(test_mus[2], np.diag(test_vars[2]))\n",
    "\n",
    "print(np.mean(np.sum(sps.multivariate_normal(avg_train_mus[0], avg_train_logvars[0]).pdf(test_2.rvs(1)))))\n",
    "print(np.mean(np.sum(sps.multivariate_normal(avg_train_mus[1], avg_train_logvars[1]).pdf(test_2.rvs(1)))))\n",
    "print(np.mean(np.sum(sps.multivariate_normal(avg_train_mus[2], avg_train_logvars[2]).pdf(test_2.rvs(1)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = K.random_normal(shape=(100, z_dim), mean=0., stddev=1.0)\n",
    "\n",
    "dist_a1 = train_mus[0] + K.exp(train_logvars[0]) * eps\n",
    "dist_a2 = train_mus[2] + K.exp(train_logvars[2]) * eps\n",
    "dist_b1 = train_mus[10] + K.exp(train_logvars[10]) * eps\n",
    "dist_b2 = train_mus[14] + K.exp(train_logvars[14]) * eps\n",
    "\n",
    "\n",
    "m_a1, std_a1 = np.mean(np.array(dist_a1)), np.std(np.array(dist_a1))\n",
    "m_a2, std_a2 = np.mean(np.array(dist_a2)), np.std(np.array(dist_a2))\n",
    "m_b1, std_b1 = np.mean(np.array(dist_b1)), np.std(np.array(dist_b1))\n",
    "m_b2, std_b2 = np.mean(np.array(dist_b2)), np.std(np.array(dist_b2))\n",
    "\n",
    "\n",
    "x_a1 = np.random.normal(m_a1, std_a1, 100)\n",
    "x_a2 = np.random.normal(m_a2, std_a2, 100)\n",
    "x_b1 = np.random.normal(m_b1, std_b1, 100)\n",
    "x_b2 = np.random.normal(m_b2, std_b2, 100)\n",
    "\n",
    "\n",
    "#######################\n",
    "multivariate_a1 = scipy.stats.multivariate_normal(train_mus[0], np.diag(np.exp(train_logvars[0])))\n",
    "multivariate_a2 = scipy.stats.multivariate_normal(train_mus[2], np.diag(np.exp(train_logvars[2])))\n",
    "multivariate_b1 = scipy.stats.multivariate_normal(train_mus[10], np.diag(np.exp(train_logvars[10])))\n",
    "multivariate_b2 = scipy.stats.multivariate_normal(train_mus[14], np.diag(np.exp(train_logvars[14])))\n",
    "\n",
    "multivariate_1 = scipy.stats.multivariate_normal(avg_train_mus[0], np.diag(np.exp(avg_train_logvars[0])))\n",
    "multivariate_2 = scipy.stats.multivariate_normal(avg_train_mus[1], np.diag(np.exp(avg_train_logvars[1])))\n",
    "multivariate_3 = scipy.stats.multivariate_normal(avg_train_mus[2], np.diag(np.exp(avg_train_logvars[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sample = sps.multivariate_normal.rvs(test_mus[2], np.diag(test_logvars[2]), 10)\n",
    "print(np.mean(multivariate_1.pdf(test_sample)))\n",
    "print(np.mean(multivariate_2.pdf(test_sample)))\n",
    "print(np.mean(multivariate_3.pdf(test_sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(x_a1, x_a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(x_a1, x_a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(x_a1, x_b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(x_a2, x_b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(x_a2, x_b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(x_a1, x_b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(x_b1, x_b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate_a1.pdf((multivariate_a1.rvs())), multivariate_a1.pdf((multivariate_a2.rvs()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate_a2.pdf((multivariate_b1.rvs())), multivariate_a1.pdf((multivariate_b2.rvs()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20095610f18a3268815da2e700e8452467ae104b71ca0ca74a40afa76fc500a6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
