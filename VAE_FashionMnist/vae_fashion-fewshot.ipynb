{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "# prerequisites\n",
    "from tensorflow.keras.datasets import cifar10, fashion_mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Flatten, Conv2D, Reshape, Conv2DTranspose, BatchNormalization\n",
    "from tensorflow.keras.activations import elu\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import binary_crossentropy, mean_squared_error, KLDivergence\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import stats as sps \n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# data load\n",
    "(x_tr, y_tr), (x_te, y_te) = fashion_mnist.load_data()\n",
    "x_tr, x_te = x_tr.astype('float32')/255., x_te.astype('float32')/255.\n",
    "x_tr, x_te = x_tr.reshape(x_tr.shape[0], -1), x_te.reshape(x_te.shape[0], -1)\n",
    "print(x_tr.shape, x_te.shape)\n",
    "\n",
    "\n",
    "# network parameters\n",
    "batch_size, n_epoch = 100, 50\n",
    "n_hidden, z_dim = 256, 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_f, y_f = [], [] \n",
    "rmv_idx = []\n",
    "\n",
    "for i in range(10): \n",
    "    if i % 2 != 0: \n",
    "        \n",
    "        # 1,3,5,7,9 \n",
    "        idf_i = list(np.where(y_tr == i)[0]) \n",
    "        \n",
    "        y_f.append([i]*len(idf_i))\n",
    "        x_f.append(x_tr[idf_i]) \n",
    "        \n",
    "            \n",
    "        # remove elements by index list \n",
    "        rmv_idx += idf_i\n",
    "             \n",
    "x_tr = np.delete(x_tr, rmv_idx, axis=0) \n",
    "y_tr = np.delete(y_tr, rmv_idx, axis=0) \n",
    "        \n",
    "x_f = np.array(x_f) \n",
    "y_f = np.array(y_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_tr.shape, x_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "x = Input(shape=(x_tr.shape[1:]))\n",
    "x_encoded = Dense(n_hidden, activation='relu')(x)\n",
    "x_encoded = Dense(n_hidden//2, activation='relu')(x_encoded)\n",
    "\n",
    "mu = Dense(z_dim)(x_encoded)\n",
    "log_var = Dense(z_dim)(x_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling function\n",
    "def sampling(args):\n",
    "    mu, log_var = args\n",
    "    eps = K.random_normal(shape=(batch_size, z_dim), mean=0., stddev=1.0)\n",
    "    return mu + K.exp(log_var) * eps\n",
    "\n",
    "z = Lambda(sampling, output_shape=(z_dim,))([mu, log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "z_decoder1 = Dense(n_hidden//2, activation='relu')\n",
    "z_decoder2 = Dense(n_hidden, activation='relu')\n",
    "y_decoder = Dense(x_tr.shape[1], activation='sigmoid')\n",
    "\n",
    "z_decoded = z_decoder1(z)\n",
    "z_decoded = z_decoder2(z_decoded)\n",
    "y = y_decoder(z_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 256)          200960      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 128)          32896       dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 16)           2064        dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 16)           2064        dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (100, 16)            0           dense_37[0][0]                   \n",
      "                                                                 dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (100, 128)           2176        lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (100, 256)           33024       dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (100, 784)           201488      dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.square (TFOpLambda)     (None, 16)           0           dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp (TFOpLambda)        (None, 16)           0           dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 16)           0           tf.math.square[0][0]             \n",
      "                                                                 tf.math.exp[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast (TFOpLambda)            (None, 784)          0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor (TFOpLambd (100, 784)           0           dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 16)           0           tf.__operators__.add[0][0]       \n",
      "                                                                 dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.keras.backend.binary_crossen (100, 784)           0           tf.cast[0][0]                    \n",
      "                                                                 tf.convert_to_tensor[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLambda) (None, 16)           0           tf.math.subtract[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (100,)               0           tf.keras.backend.binary_crossentr\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) (None,)              0           tf.math.subtract_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (100,)               0           tf.math.reduce_mean[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None,)              0           tf.math.reduce_sum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (100,)               0           tf.math.multiply[0][0]           \n",
      "                                                                 tf.math.multiply_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_loss (AddLoss)              (100,)               0           tf.__operators__.add_1[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 474,672\n",
      "Trainable params: 474,672\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# loss\n",
    "reconstruction_loss = binary_crossentropy(x, y) * x_tr.shape[1]\n",
    "kl_loss = 0.05* K.sum(K.square(mu) + K.exp(log_var) - log_var - 1, axis = -1)\n",
    "vae_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "# build model\n",
    "vae = Model(x, y)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer=\"rmsprop\")\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "300/300 [==============================] - 3s 6ms/step - loss: 590.6047\n",
      "Epoch 2/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 304.6155\n",
      "Epoch 3/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 293.7812\n",
      "Epoch 4/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 289.6683\n",
      "Epoch 5/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 284.9829\n",
      "Epoch 6/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 282.0215\n",
      "Epoch 7/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 279.6614\n",
      "Epoch 8/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 278.3993\n",
      "Epoch 9/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 275.7855\n",
      "Epoch 10/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 275.2856\n",
      "Epoch 11/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 273.7428\n",
      "Epoch 12/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 273.2185\n",
      "Epoch 13/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 272.0752\n",
      "Epoch 14/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 271.5567\n",
      "Epoch 15/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 271.3703\n",
      "Epoch 16/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 270.9546\n",
      "Epoch 17/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 270.6072\n",
      "Epoch 18/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 270.0707\n",
      "Epoch 19/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 269.4349\n",
      "Epoch 20/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 268.8964\n",
      "Epoch 21/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 268.9652\n",
      "Epoch 22/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 269.2501\n",
      "Epoch 23/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 268.5672\n",
      "Epoch 24/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 268.3758\n",
      "Epoch 25/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 268.1349\n",
      "Epoch 26/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 268.1269\n",
      "Epoch 27/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 267.3110\n",
      "Epoch 28/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 266.7232\n",
      "Epoch 29/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 267.3249\n",
      "Epoch 30/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 267.0139\n",
      "Epoch 31/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 267.0541\n",
      "Epoch 32/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 266.8147\n",
      "Epoch 33/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 266.3612\n",
      "Epoch 34/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 266.6718\n",
      "Epoch 35/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 266.0734\n",
      "Epoch 36/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 266.0896\n",
      "Epoch 37/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 265.6832\n",
      "Epoch 38/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 265.9774\n",
      "Epoch 39/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 265.3322\n",
      "Epoch 40/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 266.0632\n",
      "Epoch 41/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 265.3454\n",
      "Epoch 42/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 264.7046\n",
      "Epoch 43/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 264.9393\n",
      "Epoch 44/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 265.3459\n",
      "Epoch 45/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 265.9470\n",
      "Epoch 46/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 264.6154\n",
      "Epoch 47/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 264.9215\n",
      "Epoch 48/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 265.1258\n",
      "Epoch 49/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 265.6571\n",
      "Epoch 50/50\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 264.6080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a015c57cc8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "vae.fit(x_tr,\n",
    "       shuffle=True,\n",
    "       epochs=n_epoch,\n",
    "       batch_size=batch_size,\n",
    "       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 235,920\n",
      "Trainable params: 235,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build encoder\n",
    "encoder = Model(x, mu)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             multiple                  2176      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             multiple                  33024     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             multiple                  201488    \n",
      "=================================================================\n",
      "Total params: 236,688\n",
      "Trainable params: 236,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build decoder\n",
    "decoder_input = Input(shape=(z_dim,))\n",
    "_z_decoded = z_decoder1(decoder_input)\n",
    "_z_decoded = z_decoder2(_z_decoded)\n",
    "_y = y_decoder(_z_decoded)\n",
    "\n",
    "generator = Model(decoder_input, _y)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Michedev/VAE_anomaly_detection/blob/0a9eb14b7df226e8195c77d145a0f586ecbb6d67/VAE.py#L7\n",
    "def softplus(x):\n",
    "    return np.log(1+np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 256)          200960      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 128)          32896       dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 16)           2064        dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 16)           2064        dense_36[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 237,984\n",
      "Trainable params: 237,984\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "vae_enc = Model(x, [mu, log_var])\n",
    "\n",
    "vae_enc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "test_classes = []\n",
    "\n",
    "for i in range(y_f.shape[0]):\n",
    "    test_classes.append(y_f[i][0])\n",
    "    \n",
    "print(test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahalanobis Distance\n",
    "def mahalanobis(x=None, mean=None, cov=None):\n",
    "\n",
    "    x_mu = x - mean\n",
    "    inv_covmat = np.linalg.inv(cov)\n",
    "    \n",
    "    left = np.dot(x_mu, inv_covmat)\n",
    "        \n",
    "    mahal = np.dot(left, x_mu.T)\n",
    "        \n",
    "    return mahal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence_dists(mu1, mu2, log_var_1, log_var_2):\n",
    "    \n",
    "    kl_divergence_val = np.sum((log_var_1 / log_var_2) + ((np.exp(log_var_1) + (mu1-mu2)**2 ) / (2 * np.exp(log_var_2))) - (1/2)) / z_dim\n",
    "    \n",
    "    # returns divergence, if the of them identical, the result will be 0, else up to pos. inf.\n",
    "    return kl_divergence_val - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [09:42<00:00,  2.06it/s]\n"
     ]
    }
   ],
   "source": [
    "n_way = 3 # number of classes\n",
    "n_shot = 5 # number of samples per class\n",
    "\n",
    "n_trial = 0\n",
    "n_true = 0\n",
    "n_false = 0\n",
    "\n",
    "n_test = 1200\n",
    "\n",
    "g_train_images, g_train_gt_labels = np.load(str(n_way)+\"-\"+str(n_shot)+'.npz')[\"trainImage\"],np.load(str(n_way)+\"-\"+str(n_shot)+'.npz')[\"trainLabel\"]\n",
    "g_test_images, g_test_gt_labels = np.load(str(n_way)+\"-\"+str(n_shot)+'.npz')[\"testImage\"],np.load(str(n_way)+\"-\"+str(n_shot)+'.npz')[\"testLabel\"]\n",
    "g_ways = np.load(str(n_way)+\"-\"+str(n_shot)+'.npz')[\"ways\"]\n",
    "\n",
    "for ntest in tqdm(range(n_test)):\n",
    "    #print(\"Test Classes: {}\".format(test_classes))\n",
    "\n",
    "    # Load test data\n",
    "    test_images = g_test_images[ntest]\n",
    "    test_gt_labels = g_test_gt_labels[ntest]\n",
    "\n",
    "\n",
    "    train_images = g_train_images[ntest]\n",
    "    train_gt_labels = g_train_gt_labels[ntest]\n",
    "    \n",
    "    ways = g_ways[ntest]\n",
    "\n",
    "    train_mus = []\n",
    "    train_vars = []\n",
    "\n",
    "    for image in train_images:\n",
    "        res = vae_enc.predict(image)\n",
    "        mu_val = res[0][0]\n",
    "        var_val = res[1][0]\n",
    "\n",
    "        train_mus.append(mu_val)\n",
    "        train_vars.append(K.exp(var_val))\n",
    "\n",
    "\n",
    "    test_mus = []\n",
    "    test_vars = []\n",
    "\n",
    "    for image in test_images:\n",
    "        res = vae_enc.predict(image)\n",
    "        mu_val = res[0][0]\n",
    "        var_val = res[1][0]\n",
    "\n",
    "        test_mus.append(mu_val)\n",
    "        test_vars.append(K.exp(var_val))\n",
    "\n",
    "    ###########################\n",
    "    # Averaging mean's and mu's for each class\n",
    "    alpha = 1 / n_shot\n",
    "    avg_train_mus = []\n",
    "    avg_train_vars = []\n",
    "    \n",
    "    # average the mu and variance variables\n",
    "    for i in range(0,len(train_mus) - 1, n_shot):\n",
    "        \n",
    "        \n",
    "        avg_mu = np.mean(train_mus[i: i + n_shot], axis=0)\n",
    "            \n",
    "        class_mu = train_mus[i: i + n_shot]\n",
    "        class_variance = train_vars[i: i + n_shot]\n",
    "                \n",
    "        # sinif ici her bir mu variance al\n",
    "        avg_var = [0.0] * z_dim\n",
    "        for j in range(len(class_variance)):\n",
    "            \n",
    "            # For the 1st, 2nd, 3rd solutions            \n",
    "            if n_shot != 1:\n",
    "                avg_var += (( 1/n_shot * class_variance[j] ) + (1/n_shot * ((class_mu - avg_mu)**2)))\n",
    "            # If there is only 1 sample, avg_var equals to that sample's var\n",
    "            else:\n",
    "                avg_var += class_variance[j]        \n",
    "        \n",
    "        # class oriented var\n",
    "        avg_train_vars.append(avg_var)\n",
    "        \n",
    "        # class oriented mu\n",
    "        avg_train_mus.append(avg_mu)\n",
    "\n",
    "    test_pred_labels = []\n",
    "    for i in range(len(test_mus)):\n",
    "        # 1.st and 2.nd way\n",
    "        #test_dist = scipy.stats.multivariate_normal(test_mus[i], test_vars[i])\n",
    "        #test_elem = test_dist.rvs()\n",
    "        \n",
    "        # 3.rd way;\n",
    "        test_dist = torch.distributions.Normal(torch.from_numpy(test_mus[i]), torch.from_numpy(np.sqrt(test_vars[i].numpy())))\n",
    "        \n",
    "        \n",
    "        local_scores = []\n",
    "        for j in range(len(avg_train_mus)):\n",
    "            # 1.st way; MAHALANOBIS\n",
    "            #scr = mahalanobis(test_elem, avg_train_mus[j], np.diag(avg_train_vars[j])) \n",
    "            \n",
    "            # 2.nd way; PDF \n",
    "            #scr = scipy.stats.multivariate_normal(avg_train_mus[j], np.diag(avg_train_vars[j])).pdf(test_elem)    \n",
    "            \n",
    "            # 3.rd way; KL divergence\n",
    "            train_dist = torch.distributions.Normal(torch.from_numpy(avg_train_mus[j]), torch.from_numpy(np.sqrt(np.array(avg_train_vars[j]))))\n",
    "            scr = torch.distributions.kl_divergence(test_dist, train_dist).mean()\n",
    "            \n",
    "            local_scores.append(scr)\n",
    "\n",
    "        # 1.st way, min of mahalanobis distance\n",
    "        #pred_cls_idx = np.argmin(local_scores)\n",
    "        \n",
    "        # 2.nd way, maximum pdf\n",
    "        #pred_cls_idx = np.argmax(local_scores)\n",
    "    \n",
    "        # 3.rd way, min of kl divergence\n",
    "        pred_cls_idx = np.argmin(local_scores)\n",
    "        \n",
    "         \n",
    "        test_pred_labels.append(ways[pred_cls_idx])\n",
    "\n",
    "\n",
    "    for i in range(len(test_gt_labels)):\n",
    "        if test_gt_labels[i] == test_pred_labels[i]:\n",
    "            n_true += 1\n",
    "        else:\n",
    "            n_false += 1\n",
    "\n",
    "        n_trial += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_way: 3 - K-shot: 5\n",
      "Acc: 0.82333 in 1200 different trials\n"
     ]
    }
   ],
   "source": [
    "print(\"N_way: {} - K-shot: {}\".format(n_way, n_shot))\n",
    "print(\"Acc: {:.5f} in {} different trials\".format(n_true/n_trial, n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2017, -0.3135,  3.3291,  0.9331])\n",
      "tensor([0.0306, 0.0387, 0.0628, 0.0415])\n",
      "tensor([-0.0969, -0.1601,  0.9560, -1.5615])\n",
      "tensor([0.0032, 0.0028, 0.0038, 0.0035], dtype=torch.float64)\n",
      "tensor([ 0.2017, -0.3135,  3.3291,  0.9331])\n",
      "tensor([0.0306, 0.0387, 0.0628, 0.0415])\n",
      "**\n",
      "113550.78\n",
      "----\n",
      "tensor([ 0.3717, -2.4986,  0.7877,  2.2826])\n",
      "tensor([0.0123, 0.0089, 0.0066, 0.0071], dtype=torch.float64)\n",
      "tensor([ 0.2017, -0.3135,  3.3291,  0.9331])\n",
      "tensor([0.0306, 0.0387, 0.0628, 0.0415])\n",
      "**\n",
      "30562.23\n",
      "----\n",
      "tensor([ 0.3334, -0.5167,  1.2657, -0.0773])\n",
      "tensor([0.0034, 0.0029, 0.0042, 0.0034], dtype=torch.float64)\n",
      "tensor([ 0.2017, -0.3135,  3.3291,  0.9331])\n",
      "tensor([0.0306, 0.0387, 0.0628, 0.0415])\n",
      "**\n",
      "41774.69\n",
      "----\n",
      "tensor([ 0.0542, -0.2152,  2.7234,  0.3975])\n",
      "tensor([0.0054, 0.0059, 0.0094, 0.0066], dtype=torch.float64)\n",
      "tensor([ 0.2017, -0.3135,  3.3291,  0.9331])\n",
      "tensor([0.0306, 0.0387, 0.0628, 0.0415])\n",
      "**\n",
      "1479.47\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "test_dist = torch.distributions.Normal(torch.from_numpy(test_mus[i]), torch.from_numpy(test_vars[i].numpy()))\n",
    "\n",
    "print(test_dist.loc)\n",
    "print(test_dist.scale)\n",
    "\n",
    "for j in range(4):\n",
    "    train_dist = torch.distributions.Normal(torch.from_numpy(avg_train_mus[j]), torch.from_numpy(np.array(avg_train_vars[j])))\n",
    "    scr = torch.distributions.kl_divergence(test_dist, train_dist).mean()\n",
    "    \n",
    "    print(train_dist.loc)\n",
    "    print(train_dist.scale)\n",
    "    \n",
    "    print(test_dist.loc)\n",
    "    print(test_dist.scale)\n",
    "    \n",
    "    print(\"**\")\n",
    "    print(\"{:.2f}\".format(scr))\n",
    "    \n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous Mean\n",
    "# Averaging mean's and mu's for each class\n",
    "alpha = 1 / n_shot\n",
    "avg_train_mus = []\n",
    "avg_train_vars = []\n",
    "\n",
    "c = 0\n",
    "sum_mean = 0.0\n",
    "sum_var = [0.0] * z_dim\n",
    "for i in range(len(train_mus)):    \n",
    "\n",
    "    if c <= n_shot-1:\n",
    "        sum_mean += (alpha * train_mus[i])\n",
    "        weighted_train_var = [ x*alpha for x in train_vars[i] ]\n",
    "\n",
    "        for m in range(len(weighted_train_var)):\n",
    "            sum_var[m] = sum_var[m] + weighted_train_var[m]\n",
    "\n",
    "        c += 1\n",
    "\n",
    "        if c == n_shot:\n",
    "            avg_train_mus.append(sum_mean)\n",
    "            avg_train_vars.append(sum_var)\n",
    "\n",
    "            sum_mean = 0.0\n",
    "            sum_var = [0.0] * z_dim\n",
    "\n",
    "            c = 0\n",
    "\n",
    "#print(train_mus, train_vars)\n",
    "#print(avg_train_mus, avg_train_vars)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####\n",
    "#####\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = K.random_normal(shape=(100, z_dim), mean=0., stddev=1.0)\n",
    "\n",
    "dist_a1 = train_mus[0] + K.exp(train_vars[0]) * eps\n",
    "dist_b1 = train_mus[1] + K.exp(train_vars[1]) * eps\n",
    "dist_c1 = train_mus[2] + K.exp(train_vars[2]) * eps\n",
    "\n",
    "\n",
    "m_a1, std_a1 = np.mean(np.array(dist_a1)), np.std(np.array(dist_a1))\n",
    "m_b1, std_b1 = np.mean(np.array(dist_b1)), np.std(np.array(dist_b1))\n",
    "m_c1, std_c1 = np.mean(np.array(dist_c1)), np.std(np.array(dist_c1))\n",
    "\n",
    "\n",
    "x_a1 = np.random.normal(m_a1, std_a1, 100)\n",
    "x_b1 = np.random.normal(m_b1, std_b1, 100)\n",
    "x_c1 = np.random.normal(m_c1, std_c1, 100)\n",
    "\n",
    "\n",
    "#######################\n",
    "multivariate_a1 = scipy.stats.multivariate_normal(train_mus[0], np.diag(np.exp(train_vars[0])))\n",
    "multivariate_b1 = scipy.stats.multivariate_normal(train_mus[1], np.diag(np.exp(train_vars[1])))\n",
    "multivariate_c1 = scipy.stats.multivariate_normal(train_mus[2], np.diag(np.exp(train_vars[2])))\n",
    "\n",
    "multivariate_1 = scipy.stats.multivariate_normal(avg_train_mus[0], np.diag(np.exp(avg_train_vars[0])))\n",
    "multivariate_2 = scipy.stats.multivariate_normal(avg_train_mus[1], np.diag(np.exp(avg_train_vars[1])))\n",
    "multivariate_3 = scipy.stats.multivariate_normal(avg_train_mus[2], np.diag(np.exp(avg_train_vars[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(x_a1, x_a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(x_a1, x_b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(x_a1, x_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(x_b1, x_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.ks_2samp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save test data\n",
    "n_way = 3 # number of classes\n",
    "n_shot = 5 # number of samples per class\n",
    "\n",
    "n_test = 1200\n",
    "\n",
    "test_images = []\n",
    "test_gt_labels = []\n",
    "\n",
    "\n",
    "train_images = []\n",
    "train_gt_labels = []\n",
    "\n",
    "ways = []\n",
    "\n",
    "\n",
    "\n",
    "for ntest in tqdm(range(n_test)):\n",
    "    #print(\"Test Classes: {}\".format(test_classes))\n",
    "\n",
    "    local_test_images = []\n",
    "    local_test_gt_labels = []\n",
    "\n",
    "\n",
    "    local_train_images = []\n",
    "    local_train_gt_labels = []\n",
    "\n",
    "    class_selector = random.sample(range(1, len(test_classes)), n_way)\n",
    "    local_ways = []\n",
    "\n",
    "    for i in class_selector:\n",
    "        local_ways.append(test_classes[i])\n",
    "\n",
    "    #print(\"Selected Indices: {}\".format(class_selector))\n",
    "    #print(\"Selected Classes: {}\".format(ways))\n",
    "\n",
    "\n",
    "    for cls_idx in class_selector:\n",
    "\n",
    "        class_label = test_classes[cls_idx]\n",
    "        x_sample_idx = random.sample(range(0, x_f[cls_idx].shape[0]), n_shot+1)\n",
    "\n",
    "        for c, idx in enumerate(x_sample_idx):\n",
    "\n",
    "            x_sample = x_f[cls_idx][idx].reshape(-1,32,32,3)\n",
    "\n",
    "            if c == len(x_sample_idx) - 1:\n",
    "                local_test_images.append(x_sample)\n",
    "                local_test_gt_labels.append(class_label)\n",
    "            else:\n",
    "                local_train_images.append(x_sample)\n",
    "                local_train_gt_labels.append(class_label)\n",
    "\n",
    "    # add local to general list\n",
    "    test_images.append(local_test_images)\n",
    "    test_gt_labels.append(local_test_gt_labels)\n",
    "    \n",
    "    train_images.append(local_train_images)\n",
    "    train_gt_labels.append(local_train_gt_labels)\n",
    "    ways.append(local_ways)\n",
    "\n",
    "np.savez(str(n_way)+\"-\"+str(n_shot)+'.npz', trainImage=train_images, trainLabel=train_gt_labels, testImage=test_images, testLabel=test_gt_labels, ways=ways)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20095610f18a3268815da2e700e8452467ae104b71ca0ca74a40afa76fc500a6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
